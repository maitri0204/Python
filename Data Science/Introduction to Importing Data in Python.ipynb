{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading a text file\n",
    "filename = 'huck_finn.txt'\n",
    "file = open(filename, mode='r')  # 'r' is to read\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "file = open(filename, mode='w')     # 'w' is to write\n",
    "\n",
    "# Context manager with\n",
    "with open('huck_finn.txt', mode='r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing your Numpy import\n",
    "import numpy as np\n",
    "filename = 'MNIST_header.txt'\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1, usecols=[0, 2], dtype='str')\n",
    "print(data)\n",
    "\n",
    "# np.recfromcsv() - for csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating pandas DataFrames\n",
    "- Exploratory data analysis\n",
    "- Data wrangling\n",
    "- Data preprocessing\n",
    "- Building models\n",
    "- Visualization\n",
    "- Standard and best practice to use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing using pandas\n",
    "import pandas as pd\n",
    "filename = 'winequality-red.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data.head()\n",
    "data_array = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rb - read only in binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickled files\n",
    "import pickle\n",
    "with open('pickled_fruit.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = 'urbanpop.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "print(data.sheet_names)\n",
    "df1 = data.parse('1960-1966')  # sheet name, as a string\n",
    "df2 = data.parse(0)  # sheet index, as a float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAS and Stata files\n",
    "- SAS: Statistical Analysis System\n",
    "- Stata: \"Statistics\" + \"data\"\n",
    "- SAS: business analytics and biostatistics\n",
    "- Stata: academic social sciences research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SAS file\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "with SAS7BDAT('urban.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Stata files\n",
    "import pandas as pd\n",
    "data = pd.read_stata('urbanpop.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 files\n",
    "- Hierarchical Data Format version 5\n",
    "- Standard for storing large quantities of numerical data\n",
    "- Datasets can be hundreds of gigabytes or terabytes\n",
    "- HDF5 can scale to exabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing HDF5 file\n",
    "import h5py\n",
    "filename = 'H-Hi_LOSC_4_V1-815411200-4096.hdf5'\n",
    "data = h5py.File(filename, 'r')  # 'r' is to read\n",
    "print(type(data))\n",
    "\n",
    "# structure of HDF5 file\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "\n",
    "for key in data['meta'].keys():\n",
    "    print(key)\n",
    "print(np.array(data['meta']['Description']), np.array(data['meta']['Detector']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy to load matlab data\n",
    "- scipy.io.loadmat() - read .mat files\n",
    "- scipy.io.savemat() - write .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a .mat file\n",
    "import scipy.io\n",
    "filename = 'workspace.mat'\n",
    "mat = scipy.io.loadmat(filename)\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a database engine\n",
    "- SQLite database\n",
    "    - Fast and simple\n",
    "- SQLAlchemy\n",
    "    - Works with many Relational Database Management Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "# Getting table names\n",
    "tables_name = engine.table_names()\n",
    "print(tables_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow of SQL querying\n",
    "- Import packages and functions\n",
    "- Create the database engine\n",
    "- Connect to the engine\n",
    "- Query the database\n",
    "- Save query results to a DataFrame\n",
    "- Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First query\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "con = engine.connect()\n",
    "rs = con.execute('SELECT * FROM Orders')\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "df.columns = rs.keys()\n",
    "con.close()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the context manager\n",
    "# no need to close the connection\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT OrderID, OrderDate, ShipName FROM Orders')\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5)) # import 5 rows instead of all\n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pandas way to query\n",
    "import pandas as pd\n",
    "df = pd.read_sql_query('SELECT * FROM Orders', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN in Python\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "df = pd.read_sql_query('SELECT OrderID, CompanyName FROM Orders INNER JOIN Customers on Orders.CustomerID = Customers.CustomerID', engine) \n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
